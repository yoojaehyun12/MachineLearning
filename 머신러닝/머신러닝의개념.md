# 머신 러닝의 개념

## 머신 러닝 이란?
- 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학
- 애플리케이션을 수정하지 않고도 데이터를 기반으로 패턴을 학습하는 알고리즘
    - `애플리케이션을 수정하지 않고??` -->  머신러닝이 유연하게 다양한 작업에 활용 될 뿐 아니라, 새로운 데이터에 대응하기 위해 `컴퓨터가 패턴을 파악해서` 매번 코드를 변경 하지 않아도 된다는 뜻!
- 현실에 있는 매우 복잡한 조건들로 인해 기존의 소프트웨어 코드만으로는 해결하기 어려웠으나,
머신러닝으로 쉽게 해결 가능!
- 데이터마이닝, 영상인식, 음성인식, 자연어 처리 등 여러 분야 사용(이건 그리 중요한건 아님)

## 머신러닝과 기존 컴퓨터 사이언스의 차이점
- 기존 컴퓨터 사이언스는 로직을 미리 만들어서 데이터를 받아 결과를 확인하는 방식
    ```
    def X(a,b):
        result = a+b
        return result

    a = int(input('숫자입력:'))
    b = int(input('숫자입력:'))

    result = X(a,b)
    print(result)
    ```
    - 이걸 반복적으로 넣어주면 복잡하고 데이터가 너무 많아 현실적으로 어려움이있음.

    - __즉, 입력된 데이터의 패턴을 파악하여 어떤 연산이 이룰지 학습하는 과정이 머신러닝이다.__

## 머신러닝의 유형
- 지도 학습
    - 분류, 회귀, 추천 시스템, 시각/음성 감지 인지 등
    - 머신러닝 모델에게 문제(feature) 와 답(label) 제공 -> `feature는 타겟의 데이터 특징`
- 비지도 학습
    - 군집화(클러슽터링), 차원축소, 토픽 모델링, 문서 군집 등
    - 모델에게 문제(feature)만 제공

### 지도 학습 - 분류(Classfication)
- `머신 러닝의 대부분은 이진 분류 이다.`
    - 여러번의 이진 분류를 통해 __다중 분류__ 가 된다.
    - 이진 분류 : Yes(양성) or No(음성) 로 분류되는 문제
        - 당신은 비만 인가요? 답 > Y : 1, N : 0

### 지도 학습 - 회귀(Regression)
- Continuous Valued Output 예측하기
    - 쉽게 말해서 __수치 ~ 만큼__
    - 예시
        - 공부 시간으로 시험점수 예측하기
        - 집값 예측하기

## 머신러닝의 신경 써야 할 부분
- 데이터에 너무 의존적이다.(좋은 머신러닝 성능을 내기 위해서 많은 데이터가 필요! >> 데이터 과적합 되기 쉬움)
- 복잡한 머신러닝 알고리즘으로 인해 결과에 대한 논리적인 이해가 어려울 수 있음.
- 가장 중요한 것!
     - 데이터만 집어 넣으면 자동으로 최적의 결과를 낼 수 있는 것은 아니다!!!
        - 끊임없이 모델을 개선하기 위한 노력이 필요
        - 데이터 특성 파악 및 고급 능력이 필요

## 머신러닝 용어 정리
- Feature(X) - 머신러닝이 학습해야 할 데이터 R^NxM
    - 데이터 세트의 일반 속성
    - 2차원 이상의 다차원데이터에서도 많이 사용된다.
- Label, Class, Target (y) - R^Nx1 -> 무조건 열벡터!
    - Target, Label 은 열벡터 
     - Target : 학습 시 데이터의 학습을 위해 주어지는 정답 데이터
     - Label : 분류의 경우 이 타겟을 레이블로 함.
    - Class : 분류 문제에서 레이블의 종류를 의미

## ⭐⭐머신러닝 모델링 및 예측 프로세스⭐⭐
1. 데이터 세트 분리
    - 데이터를 학습, 테스트로 분리
2. 모델 학습(fit)
    - 학습 데이터를 머신러닝 알고리즘 적용해 모델 학습
3. 예측 수행(predict)
     - 학습된 모델을 이용해 테스트 데이터로 예측
4. 평가(evaluate)
    - 예측된 결과와 테스트 데이터의 실제 결괏값을 비교해서 머신러닝 모델 성능 평가!

### 훈련(학습) 데이터와 테스트 데이터가 따로 존재하는 이유
- 머신러닝 모델은 학습할 때 사용하는 데이터로부터 패턴을 학습하고 이 학습된 패턴을 기반으로 새로운 데이터에 대한 예측 수행을 하는데,
- 여기서, 모델이 이미 그 데이터를 __알고 있다면?__ 실제로 모델이 얼마나 잘 작동되는지 알 수 가 없기 때문에(신뢰 불가능) `즉, 학습 데이터와 테스트 데이터를 나누어 사용하는 것이다.`
    - 예시
        - 수학 시험을 준비 할 때, 내가 자주 풀었던 연습문제가 그대로 똑같이 시험문제로 나오게되면, 당연히 시험점수는 높게 나올 수 밖에 없겠지?? 그런데 이게 수학을 잘 알기 때문에 혹은 얘가 수학에 재능이 있구나 라는 것은 알기 어렵겠지? 내가 똑같이 푼 연습문제를 복붙한거나 다름없는데 이게 재능이란 뭔 상관? ㅇㅋ?
그래서 `그것을 판별하기 위해서 학습데이터(연습문제) 와 테스트데이터(시험문제) 를 따로 나누어 사용 해서 모델의 성능을 신뢰할 수 있게 만드는 것이 중요한거야!`

- ⭐⭐`모델의 성능을 신뢰 할 수 있게 만드는 것!`⭐⭐

## train_test_splilt
```
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size, random_state, stratify)
```
 - data : feature 데이터
 - target : label 데이터
 - test_size : 전체 데이터에서 테스트 데이터 의 비율(기본값은 25% == 0.25로 테스트 사용)
 - random_state : `train_test_splilt` 함수에서 데이터를 나눌 때 난수 발생을 제어하기 위한 매개 변수, 이를 통해 데이터를 나누는 과정에서 랜덤성을 조절할 수 있다.
 - stratify : 데이터 분할 시 원본 데이터의 비율과 동일하게 테스트를 생성하기 위해 지정하는 데이터 기준

    - `random_state` 가 필요한 이유
        - `train_test_splilt` 함수에서 데이터가 균등하게 학습데이터와 테스트데이터로 나뉘게 되는데, 여기서 랜덤성을 부여 안하게 되면, `학습데이터는 따로 테스트 데이터도 따로 나눌 수 있어`(연습문제는 1단원을 풀었는데 갑자기 시험문제로 2단원이 나올 수 있다는 것) 이러면, 모델의 성능을 제대로 알아 볼 수 없기 때문에 `random_state` 가 필요하다.
        
    - 계층적 분할(Stratify Spilt) 방식 : 모든 레이블을 균등하게 비율 적용
     - 데이터가 [0,0,0,0,0,1,1,1,1,1,2,2,2,2,2] 
        - tranin_test_split을 이용해 데이터 분할 시
            - train_set : [0,0,0,0,1,1,1,2,2]
            - test_set : [0,1,1,2,2,2]
                - 원본 데이터의 비율은 1:1:1 이지만, 랜덤하게 분할 시 한쪽으로만 데이터가 많아지거나 적게 될 수 있기 때문에
                    - 원본 데이터의 비율에 맞게 훈련세트와 테스트 세트를 분할 하는 것을 `계층적 분할` 이라고 한다.
                    - `계층적 분할` 사용 시
                        - train_set : [0,0,0,1,1,1,2,2,2]
                        - test_set : [0,0,1,1,2,2]

## 교차 검증(모의고사)
- 검증(Validation)세트
    - 전체 데이터세트에서 학습데이터 테스트데이터를 분리하자나?
        - 여기서 학습데이터에서 한번 더 학습 데이터와 검증 데이터로 분리를 하는 거야
             - 테스트 데이터로 바로 안가고 한번 검증을 걸쳐서 미리 성능을 검증 하는 거지.
                - 그 다음에 테스트 데이터로 최종적으로 성능 평가하는 거고.
                - 교차 검증은 많이 해도 됨.
- K 폴드(Fold) 교차 검증
    - k=5 일 경우, 총 5번의 학습과 검증을 수행한다는 것!
- Stratified K 폴드
    - 일반 K 폴드(K Fold) 
        - K 만큼 데이터를 나누어 검증하는 방식 -> 데이터 분포 고려 X
    - 계층적 K 폴드(Stratified K Fold) 
        - 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식
        - 학습 데이터와 검증 데이터 세트가 가지는 레이블 분포도가 유사하도록 검증 데이터 추출

- 간편한 교차 검증 - cross_val_score
    - K-Fold 클래스를 이용한 교차 검증 방법을 간편화 한 사이킷 런의 검증 함수
        ```
        cross_val_score(estimator,X,y=None,scoring=None, cv=None, n_jobs=1)
        ```    
        - estimator:모델
        - X : feature(학습 데이터)
        - y : target(테스트 데이터)
        - scoring : 예측 성능 평가 방식
            - scoring=None 을 설정하는 이유
                - 단순히 기본적인 성능 지표로 검증하겠다는 의미로, 각 폴드에서의 점수가 반환되고, 각 폴드에서의 모델 성능을 확인 할 수 있기 때문에
        - cv : 폴드의 개수
        - n_jobs : 사용할 CPU 개수
            - n_jobs=-1 >> 모든 CPU 사용

- ⭐⭐교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 하는 `GridSearchCV`⭐⭐
    - 사이킷 런에서 이것을 이용해 분류, 회귀 모델 알고리즘에 __하이퍼 파라미터__ 를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출 가능!
        - `하이퍼 파라미터` 란?
            - 머신러닝의 개별적인 모델에 입력하는 값
            - 모델이 학습하는 것이 아닌 개발자가 직접 넣어줘야 하는 값
            - 이것을 통해 모델의 성능이 조절되어 __최적튜닝__ 을 할 수 있다.
    
    ```
    GridSearchCV(estimator,param_grid,cv, refit=True,return_train_score)
    ```
    - estimator : 모델
    - param_grid : 하이퍼 파라미터의 목록이 들어있는 딕셔너리, 여러 개의 딕셔너리 이용 가능
    - cv : 폴드 개수
    - refit : 가장 좋은 파라미터 설정으로 재학습 시켜줌.
    - return_train_score : 훈련 결과 점수 확인 가능

## 데이터 전처리(Preprocessing)
### 데이터 인코딩
- 머신러닝 알고리즘은 문자열 데이터 속성을 받지 않음
- 문자형 카테고리형 속성은 모두 숫자값으로 변환/인코딩 되어야 함.
- 영상 편집 할 때 편집하기 전 영상을 mp4,avi 등으로 변환 하는 거랑 비슷하다 생각하면 돼.

    - 레이블 인코딩
        - [청바지,원피스,청바지,치마,청바지] => [0,2,0,1,0]
    - ⭐원-핫 인코딩⭐
        - 원-핫 인코딩으로 만들어진 컬럼 : dummy 특성
        - Feature 유형에 따라 새로운 Feature를 추가해서(열이 늘어남) 고유 값에 해당하는 컬럼에만 1표시, 나머지는 0 표시

        |상품분류_청바지|상품분류_치마|상품분류_원피스|
        |---|---|---|
        |1|0|0|
        |0|1|0|
        |0|0|1|
        |0|0|1|
        |1|0|0|
        |0|1|0|
        

- Feature Scaling
    
    ![Alt text](image.png)


